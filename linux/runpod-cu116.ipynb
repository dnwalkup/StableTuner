{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StableTuner v0.1.1 for Linux"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original version https://github.com/devilismyfriend/StableTuner\n",
    "<br>\n",
    "STv1.0 Update (12/16/2022)\n",
    "<br><br>\n",
    "Testing on docker image dnwalkup/cuda:116-cudnn8-devel-u2004:\n",
    "<br>\n",
    "* Ubuntu 20.04, Nvidia CUDNN 8, CUDA 1.16 <br>\n",
    "* PIP'd - gDown, wget, ftfy, OmegaConf, tqdm, tensorboard, transfomers, triton, pillow, iPython, pycuda, ipywidgets, jupyterlab <br>\n",
    "* APT'd - zip, unzip, rename, python3, python3-apt, python3-diskutils, python3-pip <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Global Variables and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***** DATASET ***** #\n",
    "goog_dataset_url = ''\n",
    "# Google url for your training dataset (e.g. instance images or user images). Use zip file.\n",
    "\n",
    "backup_dataset_url = ''\n",
    "# Hugging face, dropbox, etc. if google is capping your bandwidth for your training dataset (e.g. instance images or user images). Use zip file.\n",
    "\n",
    "dataset_repeats = 1\n",
    "# How many times would you like to repeat the dataset? The default of 1 here usually works well.\n",
    "\n",
    "\n",
    "# ***** PRIOR PRESERVATION LOSS MITIGATION ***** #\n",
    "use_regularization = False\n",
    "# Do you want to use regularization & prior preservation loss (e.g. class images) in your training? If so, this should be True.\n",
    "\n",
    "goog_regimg_url = ''\n",
    "# Google url for your regularization images (e.g. class images). Use zip file.\n",
    "\n",
    "backup_regimg_url = ''\n",
    "# Hugging face, dropbox, etc. if google is capping your bandwith for your regularization images (e.g. class images). Use zip file.\n",
    "\n",
    "\n",
    "# ***** GENERAL SETTINGS ***** #\n",
    "sd_base_model = 'SDv15'\n",
    "# Input the model you'd like to use. Options are 'SDv14', 'SDv15', 'SDv20-512', 'SDv20-768', 'SDv21-512', 'SDv21-768'. Default is 'SDv15'.\n",
    "\n",
    "seed = ''\n",
    "# Leave empty for a random seed.\n",
    "\n",
    "google_data_cap = False\n",
    "# Is google capping your bandwidth and not letting you download your files? If so, this needs to be true.\n",
    "\n",
    "txt_file_caption = False\n",
    "# If you have text files you'd like to use for captions, change to True.\n",
    "\n",
    "aspect_ratio_bucketing = False\n",
    "# If you don't want to limit yourself to square 1:1 dataset images, change to True.\n",
    "\n",
    "sample_at_start = False\n",
    "# Samples (and saves?) an image on the start of training to help track progress. Default is False.\n",
    "\n",
    "auto_balance = False\n",
    "# Will balance the number of images in each concept dataset to match the minimum number of images in any concept dataset\n",
    "\n",
    "save_n_epoch = 5\n",
    "# Save every n epochs to help prevent overtraining.\n",
    "\n",
    "train_txt_encoder = True\n",
    "# Whether or not to train the text encoder.\n",
    "\n",
    "mixed_precision = 'fp16'\n",
    "# Whether to use mixed precision. Choose between 'no', 'fp16' and 'bf16'.\n",
    "# Bf16 requires PyTorch >= 1.10 and an Nvidia Ampere GPU.\n",
    "\n",
    "\n",
    "# ***** ADVANCED SETTINGS ***** #\n",
    "prior_preservation_weight = 1.0\n",
    "# Variable only used if 'use_class_images' is True.\n",
    "\n",
    "cudnn_benchmark = False\n",
    "# This enables or disables CUDNN benchmarking. Default is disabled (False).\n",
    "\n",
    "txt_encoder_training_epoch = 999999999999999\n",
    "# The epoch at which the text encoder is no longer trained\n",
    "\n",
    "new_latent_cache = True\n",
    "# Regenerate latent cache. Necessary if you've made changes to batch size.\n",
    "\n",
    "save_latents_cache = False\n",
    "# Needs description\n",
    "\n",
    "add_reg_img_dataset = False\n",
    "# Will generate and/or add existing regularization images to the dataset (does not enable prior preservation loss).\n",
    "\n",
    "train_1024 = False\n",
    "# If you want to train at 1024 resolution, change to true.\n",
    "\n",
    "\n",
    "import os, gc, random\n",
    "from subprocess import getoutput\n",
    "from IPython.display import clear_output\n",
    "\n",
    "clear_output()\n",
    "print('Imports complete')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Apt Dependencies for Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt update\n",
    "!apt install -y git\n",
    "!apt install -y nvidia-cuda-toolkit\n",
    "!apt install -y zip\n",
    "!apt install -y unzip\n",
    "\n",
    "clear_output()\n",
    "print('Apt installs complete')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Pip Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install scikit-image\n",
    "!python3 -m pip install scipy\n",
    "!python3 -m pip install numpy\n",
    "!python3 -m pip install requests\n",
    "!python3 -m pip install bitsandbytes\n",
    "!python3 -m pip install accelerate==0.15.0\n",
    "!python3 -m pip install huggingface\n",
    "!python3 -m pip install albumentations\n",
    "!python3 -m pip install opencv-python\n",
    "!python3 -m pip install einops\n",
    "!python3 -m pip install pytorch_lightning\n",
    "!python3 -m pip install bitsandbytes==0.35.0\n",
    "!python3 -m pip install safetensors\n",
    "!python3 -m pip install diffusers\n",
    "\n",
    "clear_output()\n",
    "print('Pip installs complete')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install xFormers and Final Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_CardName = getoutput('nvidia-smi --query-gpu=name --format=csv,noheader')\n",
    "\n",
    "if '3090' in GPU_CardName:\n",
    "    !python3 -m pip install https://huggingface.co/dnwalkup/xformers-precompiles/resolve/main/RTX3090-xf14-cu116-py38/xformers-0.0.14.dev0-cp38-cp38-linux_x86_64.whl\n",
    "    !python3 -m pip uninstall -y torch torchvision\n",
    "    !python3 -m pip install https://download.pytorch.org/whl/cu116/torch-1.12.1%2Bcu116-cp38-cp38-linux_x86_64.whl\n",
    "    !python3 -m pip install https://download.pytorch.org/whl/cu116/torchvision-0.13.1%2Bcu116-cp38-cp38-linux_x86_64.whl\n",
    "    !python3 -m pip install timm\n",
    "    clear_output()\n",
    "    print('xFormers and pyTorch installs complete')\n",
    "elif 'A5000' in GPU_CardName:\n",
    "    !python3 -m pip install https://huggingface.co/dnwalkup/xformers-precompiles/resolve/main/A5000-xf14-cu116-py38/xformers-0.0.14.dev0-cp38-cp38-linux_x86_64.whl\n",
    "    !python3 -m pip uninstall -y torch torchvision\n",
    "    !python3 -m pip install https://download.pytorch.org/whl/cu116/torch-1.12.1%2Bcu116-cp38-cp38-linux_x86_64.whl\n",
    "    !python3 -m pip install https://download.pytorch.org/whl/cu116/torchvision-0.13.1%2Bcu116-cp38-cp38-linux_x86_64.whl\n",
    "    !python3 -m pip install timm\n",
    "    clear_output()\n",
    "    print('xFormers and pyTorch installs complete')\n",
    "else:\n",
    "    print('No prebuilt xformers available for your card')\n",
    "\n",
    "del GPU_CardName\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Necessary Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('/workspace/scripts')\n",
    "os.chdir('/workspace/scripts')\n",
    "\n",
    "os.system('wget -O trainer.py https://github.com/dnwalkup/StableTuner/raw/main/linux/scripts/trainer.py')\n",
    "os.system('wget -O converters.py https://github.com/dnwalkup/StableTuner/raw/main/linux/scripts/converters.py')\n",
    "\n",
    "clear_output()\n",
    "print('Training files downloaded')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('/workspace/dataset')\n",
    "os.chdir('/workspace/dataset')\n",
    "\n",
    "if not google_data_cap:\n",
    "    os.system('gdown --fuzzy $goog_dataset_url -O dataset.zip')\n",
    "else:\n",
    "    os.system('wget -O dataset.zip $other_dataset_url')\n",
    "\n",
    "os.system('unzip dataset.zip')\n",
    "os.remove('/workspace/dataset/dataset.zip')\n",
    "\n",
    "for instance_items in os.scandir(os.getcwd()):\n",
    "    if instance_items.is_dir():\n",
    "        INSTANCE_DIR_TMP = instance_items.path\n",
    "\n",
    "os.rename(INSTANCE_DIR_TMP,\"user_images\")\n",
    "\n",
    "DATASET_DIR = '/workspace/dataset/user_images'\n",
    "\n",
    "os.chdir(DATASET_DIR)\n",
    "os.system('find . -name \"* *\" -type f | rename \"s/ /_/g\"')\n",
    "\n",
    "del instance_items\n",
    "del INSTANCE_DIR_TMP\n",
    "gc.collect()\n",
    "\n",
    "clear_output()\n",
    "print('Instance images downloaded and unzipped')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Regularization Images\n",
    "Only used if you have \"use_regularization\" set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_regularization:\n",
    "\n",
    "    os.mkdir('/workspace/regularization')\n",
    "    os.chdir('/workspace/regularization')\n",
    "\n",
    "    if not google_data_cap:\n",
    "        os.system('gdown --fuzzy $goog_regimg_url -O reg_images.zip')\n",
    "    else:\n",
    "        os.system('wget -O reg_images.zip $other_regimg_url')\n",
    "\n",
    "    os.system('unzip reg_images.zip')\n",
    "    os.remove('reg_images.zip')\n",
    "\n",
    "    for reg_items in os.scandir(os.getcwd()):\n",
    "        if reg_items.is_dir():\n",
    "            REG_DIR_TMP = reg_items.path\n",
    "\n",
    "    os.rename(REG_DIR_TMP,'reg_images')\n",
    "\n",
    "    CLASS_DIR = '/workspace/regularization/reg_images'\n",
    "\n",
    "    os.chdir(CLASS_DIR)\n",
    "    os.system('find . -name \"* *\" -type f | rename \"s/ /_/g\"')\n",
    "\n",
    "    del reg_items\n",
    "    del REG_DIR_TMP\n",
    "    gc.collect()\n",
    "\n",
    "    clear_output()\n",
    "    print('Regularization images downloaded and unzipped')\n",
    "else:\n",
    "    print('Please move on to the next cell')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Final Training Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cudnn_benchmark:\n",
    "    cudnn_benchmark_args = ''\n",
    "else:\n",
    "    cudnn_benchmark_args = '--disable_cudnn_benchmark=True'\n",
    "\n",
    "if txt_file_caption:\n",
    "    txt_file_caption_args = '--use_text_files_as_captions=True'\n",
    "else:\n",
    "    txt_file_caption_args = ''\n",
    "\n",
    "if aspect_ratio_bucketing:\n",
    "    aspect_ratio_bucketing_args = '--use_bucketing=True'\n",
    "    sample_aspect_ratio_args = '--sample_aspect_ratios'\n",
    "else:\n",
    "    aspect_ratio_bucketing_args = ''\n",
    "    sample_aspect_ratio_args = ''\n",
    "\n",
    "if new_latent_cache:\n",
    "    new_latent_cache_args = '--regenerate_latent_cache=True'\n",
    "else:\n",
    "    new_latent_cache_args = ''\n",
    "\n",
    "if save_latents_cache:\n",
    "    save_latents_cache_args = '--save_latents_cache=True'\n",
    "else:\n",
    "    save_latents_cache = ''\n",
    "\n",
    "if sample_at_start:\n",
    "    sample_at_start_args = '--sample_on_training_start=True'\n",
    "else:\n",
    "    sample_at_start_args = ''\n",
    "\n",
    "if add_reg_img_dataset:\n",
    "    add_reg_img_dataset_args = '--add_class_images_to_dataset=True'\n",
    "else:\n",
    "    add_reg_img_dataset_args = ''\n",
    "\n",
    "if auto_balance:\n",
    "    auto_balance_args = '--auto_balance_concept_datasets=True'\n",
    "else:\n",
    "    auto_balance_args = ''\n",
    "\n",
    "if train_txt_encoder:\n",
    "    train_txt_encoder_args = '--train_text_encoder=True'\n",
    "else:\n",
    "    train_txt_encoder = ''\n",
    "\n",
    "if sd_base_model == 'SDv14':\n",
    "    sd_base_model_args = '--pretrained_model_name_or_path=CompVis/stable-diffusion-v1-4'\n",
    "    resolution_args = '--resolution=512'\n",
    "elif sd_base_model == 'SDv20-512':\n",
    "    sd_base_model_args = '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-base'\n",
    "    resolution_args = '--resolution=512'\n",
    "elif sd_base_model == 'SDv20-768':\n",
    "    sd_base_model_args = '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2'\n",
    "    resolution_args = '--resolution=768'\n",
    "elif sd_base_model == 'SDv21-512':\n",
    "    sd_base_model_args = '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-1-base'\n",
    "    resolution_args = '--resolution=512'\n",
    "elif sd_base_model == 'SDv21-768':\n",
    "    sd_base_model_args = '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-1'\n",
    "    resolution_args = '--resolution=768'\n",
    "else:\n",
    "    sd_base_model_args = '--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5'\n",
    "    resolution_args = '--resolution=512'\n",
    "\n",
    "if train_1024:\n",
    "    resolution_args = '--resolution=1024'\n",
    "\n",
    "if use_regularization:\n",
    "    prior_preservation = ''\n",
    "    #prior_preservation_weight is user set\n",
    "    class_dir_args = '--class arg=$CLASS_DIR'\n",
    "else:\n",
    "    prior_preservation = ''\n",
    "    class_dir_args = ''\n",
    "\n",
    "if seed == '' or seed == '0':\n",
    "  seed = random.randint(1, 999999)\n",
    "else:\n",
    "  seed = int(seed)\n",
    "\n",
    "output_dir = '/workspace/output_model'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch --mixed_precision=$mixed_precision /workspace/scripts/trainer.py \\\n",
    "    $cudnn_benchmark_args \\\n",
    "    $txt_file_caption_args \\\n",
    "    $sd_base_model_args \\\n",
    "    \"--pretrained_vae_name_or_path=\" \\\n",
    "    --output_dir=$output_dir \\\n",
    "    --seed=$seed \\\n",
    "    $resolution_args \\\n",
    "    \"--train_batch_size=1\" \\\n",
    "    \"--num_train_epochs=100\" \\\n",
    "    --mixed_precision=$mixed_precision \\\n",
    "    --stop_text_encoder_training=$txt_encoder_training_epoch \\\n",
    "    $aspect_ratio_bucketing_args \\\n",
    "    $sample_aspect_ratio_args \\\n",
    "    \"--use_8bit_adam\" \\\n",
    "    \"--gradient_checkpointing\" \\\n",
    "    \"--gradient_accumulation_steps=1\" \\\n",
    "    \"--learning_rate=3e-6\" \\\n",
    "    \"--lr_warmup_steps=0\" \\\n",
    "    \"--lr_scheduler=constant\" \\\n",
    "    $new_latent_cache_args \\\n",
    "    $save_latents_cache_args \\\n",
    "    \"--concepts_list=/workspace/stabletune_concept_list.json\" \\\n",
    "    $auto_balance_args\n",
    "    \"--num_class_images=0\" \\\n",
    "    $add_reg_img_dataset_args \\\n",
    "    --save_every_n_epoch=$save_n_epoch \\\n",
    "    $train_txt_encoder \\\n",
    "    $sample_at_start_args \\\n",
    "    \"--sample_height=512\" \\\n",
    "    \"--sample_width=512\" \\\n",
    "    --dataset_repeats=$dataset_repeats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
