{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StableTuner v0.1.1 for Linux"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original version https://github.com/devilismyfriend/StableTuner\n",
    "<br>\n",
    "STv1.0 Update (12/16/2022)\n",
    "<br><br>\n",
    "Testing on docker image dnwalkup/cuda:116-cudnn8-devel-u2004:\n",
    "<br>\n",
    "* Ubuntu 20.04, Nvidia CUDNN 8, CUDA 1.16 <br>\n",
    "* PIP'd - gDown, wget, ftfy, OmegaConf, tqdm, tensorboard, transfomers, triton, pillow, iPython, pycuda, ipywidgets, jupyterlab <br>\n",
    "* APT'd - zip, unzip, rename, python3, python3-apt, python3-diskutils, python3-pip <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Global Variables and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************      DATASET\n",
    "goog_dataset_url = ''\n",
    "# Google url for your training dataset (e.g. instance images or user images). Use zip file.\n",
    "\n",
    "backup_dataset_url = ''\n",
    "# Hugging face, dropbox, etc. if google is capping your bandwidth for your training dataset (e.g. instance images or user images). Use zip file.\n",
    "\n",
    "dataset_repeats_var = 1\n",
    "# How many times would you like to repeat the dataset? The default of 1 here usually works well.\n",
    "\n",
    "\n",
    "# ****************************************      PRIOR PRESERVATION LOSS MITIGATION\n",
    "use_regularization = False\n",
    "# Do you want to use regularization & prior preservation loss (e.g. class images) in your training? If so, this should be True.\n",
    "\n",
    "goog_regimg_url = ''\n",
    "# Google url for your regularization images (e.g. class images). Use zip file.\n",
    "\n",
    "backup_regimg_url = ''\n",
    "# Hugging face, dropbox, etc. if google is capping your bandwith for your regularization images (e.g. class images). Use zip file.\n",
    "\n",
    "num_class_images_var = 0\n",
    "# Enter number of regularization images you would like to generate or already exist in your directory.\n",
    "\n",
    "\n",
    "# ****************************************      TRAINING SETTINGS\n",
    "# TIP #1: What is an \"epoch\"?\n",
    "# One epoch is one run through your dataset, in other words, one epoch is the number of steps it takes\n",
    "# to \"view\" each image once. (-morbuto)\n",
    "#\n",
    "# TIP #2: For best results, use a low learning rate, high batch size, and a captioned dataset (-devilismyfriend)\n",
    "#\n",
    "# TIP #3: Maths\n",
    "# Number of dataset images / batch size = epoch size\n",
    "# For example, a dataset of 100 images and batch size 4 will have 25 steps per epoch. (-morbuto)\n",
    "\n",
    "batch_size_var = 16\n",
    "# Play with this number. If you run out of VRAM, lower it.\n",
    "\n",
    "train_epochs_var = 100\n",
    "# 50 to 600 epochs will be the right range for most trainings. (-morbuto)\n",
    "\n",
    "learning_rate_var = 1e-6\n",
    "# 3e-6 to 5e-7 will be the right range for most trainings.\n",
    "\n",
    "save_n_epoch_var = 25\n",
    "# Save every n epochs to help prevent overtraining.\n",
    "\n",
    "\n",
    "# ****************************************      GENERAL SETTINGS \n",
    "sd_base_model = 'SDv15'\n",
    "# Input the model you'd like to use.\n",
    "# Options are 'SDv14', 'SDv15', 'SDv20-512', 'SDv20-768', 'SDv21-512', 'SDv21-768'. Default is 'SDv15'.\n",
    "\n",
    "seed_var = ''\n",
    "# Leave empty for a random seed.\n",
    "\n",
    "google_data_cap = False\n",
    "# Is google capping your bandwidth and not letting you download your files? If so, this needs to be true.\n",
    "\n",
    "aspect_ratio_bucketing = False\n",
    "# If you don't want to limit yourself to square 1:1 dataset images, change to True.\n",
    "\n",
    "auto_balance = False\n",
    "# Will balance the number of images in each concept dataset to match the minimum number of images in any concept dataset\n",
    "\n",
    "train_txt_encoder = True\n",
    "# Whether or not to train the text encoder.\n",
    "\n",
    "use_vae = True\n",
    "# Use the VAE with training. Default is True.\n",
    "\n",
    "output_dir_var = '/workspace/output_model'\n",
    "# Directory for output including diffusers, checkpoints, and inference samples.\n",
    "\n",
    "mixed_precision_var = 'fp16'\n",
    "# Whether to use mixed precision. Choose between 'no', 'fp16' and 'bf16'.\n",
    "# Bf16 requires PyTorch >= 1.10 and an Nvidia Ampere GPU.\n",
    "\n",
    "\n",
    "# ****************************************      TOKEN SETTINGS\n",
    "txt_file_caption = False\n",
    "# If you have text files you'd like to use for captions, change to True.\n",
    "\n",
    "use_img_captions = False\n",
    "# If you want to use the names of each image as captions, change to True.\n",
    "\n",
    "instance_prompt = ''\n",
    "# Add a unique identifier here if you want a specific token trained to call your person or style.\n",
    "\n",
    "class_prompt = ''\n",
    "# Add a unique identifier here if you want a specific token trained for the class.\n",
    "\n",
    "\n",
    "# ****************************************      SAVE SAMPLE SETTINGS\n",
    "sample_progress = False\n",
    "# Do you want to generate inference samples as you train?\n",
    "\n",
    "sample_height_var, sample_width_var = 768, 768\n",
    "# Width & height for samples\n",
    "\n",
    "sample_at_start = False\n",
    "# Samples (and saves?) an image on the start of training to help track progress. Default is False.\n",
    "\n",
    "sample_prompt = ''\n",
    "# Insert the prompt would you like to use for your samples\n",
    "\n",
    "num_samples = 0\n",
    "# How many inference samples to generate?\n",
    "\n",
    "\n",
    "# ****************************************     ADVANCED SETTINGS\n",
    "prior_preservation_weight = 1.0\n",
    "# Variable only used if 'use_class_images' is True.\n",
    "\n",
    "cudnn_benchmark = False\n",
    "# This enables or disables CUDNN benchmarking. Default is disabled (False).\n",
    "\n",
    "txt_encoder_training_epoch_var = 999999999999999\n",
    "# The epoch at which the text encoder is no longer trained\n",
    "\n",
    "new_latent_cache = True\n",
    "# Regenerate latent cache. Necessary if you've made changes to batch size.\n",
    "\n",
    "save_latents_cache = False\n",
    "# Needs description\n",
    "\n",
    "add_reg_img_dataset = False\n",
    "# Will generate and/or add existing regularization images to the dataset (does not enable prior preservation loss).\n",
    "\n",
    "train_1024 = False\n",
    "# If you want to train at 1024 resolution, change to True.\n",
    "\n",
    "use_8bit_adam = True\n",
    "# Whether or not to use 8-bit Adam from bitsandbytes. Default is True.\n",
    "\n",
    "use_gradient_checkpointing = True\n",
    "# Whether or not to use gradient checkpointing to save memory at the expense of slower backward pass.\n",
    "\n",
    "gradient_accumulation_steps_var = 1\n",
    "# Number of updates steps to accumulate before performing a backward/update pass.\n",
    "\n",
    "scheduler_var = 'constant'\n",
    "# Scheduler type to use.Choose between 'linear', 'cosine', 'cosine_with_restarts', 'polynomial',\n",
    "# 'constant', 'constant_with_warmup'\n",
    "\n",
    "scheduler_warmup_var = 0\n",
    "# Number of steps for the warmup in the scheduler.\n",
    "\n",
    "use_concepts = False\n",
    "# Use multiple concepts via concepts file? Will overwrite parameters like instance_prompt, class_prompt, etc.\n",
    "\n",
    "concepts_file = '/workspace/stabletune_concept_list.json'\n",
    "# json file containing concepts\n",
    "\n",
    "\n",
    "import os, gc, random\n",
    "from subprocess import getoutput\n",
    "from IPython.display import clear_output\n",
    "\n",
    "clear_output()\n",
    "print('Imports complete')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Pip Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('python3 -m pip install scikit-image')\n",
    "os.system('python3 -m pip install scipy')\n",
    "os.system('python3 -m pip install numpy')\n",
    "os.system('python3 -m pip install huggingface')\n",
    "os.system('python3 -m pip install albumentations')\n",
    "os.system('python3 -m pip install opencv-python')\n",
    "os.system('python3 -m pip install einops')\n",
    "os.system('python3 -m pip install pytorch_lightning')\n",
    "os.system('python3 -m pip install safetensors')\n",
    "os.system('python3 -m pip install diffusers')\n",
    "\n",
    "clear_output()\n",
    "print('Pip installs complete')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install xFormers and Final Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_CardName = getoutput('nvidia-smi --query-gpu=name --format=csv,noheader')\n",
    "\n",
    "if '3090' in GPU_CardName:\n",
    "    os.system('python3 -m pip install https://huggingface.co/dnwalkup/xformers-precompiles/resolve/main/RTX3090-xf14-cu116-py38/xformers-0.0.14.dev0-cp38-cp38-linux_x86_64.whl')\n",
    "    os.system('python3 -m pip uninstall -y torch')\n",
    "    os.system('python3 -m pip install https://download.pytorch.org/whl/cu116/torch-1.12.1%2Bcu116-cp38-cp38-linux_x86_64.whl')\n",
    "    os.system('python3 -m pip install https://download.pytorch.org/whl/cu116/torchvision-0.13.1%2Bcu116-cp38-cp38-linux_x86_64.whl')\n",
    "    os.system('python3 -m pip install timm')\n",
    "    del GPU_CardName\n",
    "    gc.collect()\n",
    "    clear_output()\n",
    "    print('xFormers and pyTorch installs complete')\n",
    "\n",
    "elif 'A5000' in GPU_CardName:\n",
    "    os.system('python3 -m pip install https://huggingface.co/dnwalkup/xformers-precompiles/resolve/main/A5000-xf14-cu116-py38/xformers-0.0.14.dev0-cp38-cp38-linux_x86_64.whl')\n",
    "    os.system('python3 -m pip uninstall -y torch')\n",
    "    os.system('python3 -m pip install https://download.pytorch.org/whl/cu116/torch-1.12.1%2Bcu116-cp38-cp38-linux_x86_64.whl')\n",
    "    os.system('python3 -m pip install https://download.pytorch.org/whl/cu116/torchvision-0.13.1%2Bcu116-cp38-cp38-linux_x86_64.whl')\n",
    "    os.system('python3 -m pip install timm')\n",
    "    del GPU_CardName\n",
    "    gc.collect()\n",
    "    clear_output()\n",
    "    print('xFormers and pyTorch installs complete')\n",
    "\n",
    "else:\n",
    "    print('No prebuilt xformers available for your card. You may struggle with speed and vram.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Necessary Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('/workspace/scripts'):\n",
    "    os.mkdir('/workspace/scripts')\n",
    "os.chdir('/workspace/scripts')\n",
    "\n",
    "os.system('wget -O trainer.py https://github.com/dnwalkup/StableTuner/raw/main/linux/scripts/trainer.py')\n",
    "os.system('wget -O converters.py https://github.com/dnwalkup/StableTuner/raw/main/linux/scripts/converters.py')\n",
    "\n",
    "#clear_output()\n",
    "print('Training files downloaded')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('/workspace/dataset'):\n",
    "    os.mkdir('/workspace/dataset')\n",
    "\n",
    "os.chdir('/workspace/dataset')\n",
    "\n",
    "if not google_data_cap:\n",
    "    os.system(f'gdown -O dataset.zip --fuzzy {goog_dataset_url}')\n",
    "else:\n",
    "    os.system(f'wget -O dataset.zip {backup_dataset_url}')\n",
    "\n",
    "if os.path.exists('/workspace/dataset/dataset.zip'):\n",
    "    os.system('unzip dataset.zip')\n",
    "    os.remove('/workspace/dataset/dataset.zip')\n",
    "else:\n",
    "    print('Check your settings, it looks like the dataset is not there')\n",
    "\n",
    "for instance_items in os.scandir(os.getcwd()):\n",
    "    if instance_items.is_dir():\n",
    "        INSTANCE_DIR_TMP = instance_items.path\n",
    "\n",
    "os.rename(INSTANCE_DIR_TMP,\"user_images\")\n",
    "\n",
    "DATASET_DIR = '/workspace/dataset/user_images'\n",
    "\n",
    "os.chdir(DATASET_DIR)\n",
    "os.system('find . -name \"* *\" -type f | rename \"s/ /_/g\"')\n",
    "\n",
    "del instance_items\n",
    "del INSTANCE_DIR_TMP\n",
    "gc.collect()\n",
    "\n",
    "clear_output()\n",
    "print('Instance images downloaded and unzipped')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Regularization Images\n",
    "Only used if you have \"use_regularization\" set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_regularization:\n",
    "    \n",
    "    if not os.path.exists('/workspace/regularization'):\n",
    "        os.mkdir('/workspace/regularization')\n",
    "    \n",
    "    os.chdir('/workspace/regularization')\n",
    "\n",
    "    if not google_data_cap:\n",
    "        os.system(f'gdown -O reg_images.zip --fuzzy {goog_regimg_url}')\n",
    "    else:\n",
    "        os.system(f'wget -O reg_images.zip {backup_regimg_url}')\n",
    "\n",
    "    if os.path.exists('/workspace/regularization/reg_images.zip'):\n",
    "        os.system('unzip reg_images.zip')\n",
    "        os.remove('/workspace/regularization/reg_images.zip')\n",
    "    else:\n",
    "        print('Check your settings, it looks like the regularization images are not there')\n",
    "\n",
    "    for reg_items in os.scandir(os.getcwd()):\n",
    "        if reg_items.is_dir():\n",
    "            REG_DIR_TMP = reg_items.path\n",
    "\n",
    "    os.rename(REG_DIR_TMP,'reg_images')\n",
    "\n",
    "    CLASS_DIR = '/workspace/regularization/reg_images'\n",
    "\n",
    "    os.chdir(CLASS_DIR)\n",
    "    os.system('find . -name \"* *\" -type f | rename \"s/ /_/g\"')\n",
    "\n",
    "    del reg_items\n",
    "    del REG_DIR_TMP\n",
    "    gc.collect()\n",
    "\n",
    "    clear_output()\n",
    "    print('Regularization images downloaded and unzipped')\n",
    "else:\n",
    "    print('Please move on to the next cell')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Final Training Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cudnn_benchmark:\n",
    "    cudnn_benchmark_args = ''\n",
    "else:\n",
    "    cudnn_benchmark_args = '--disable_cudnn_benchmark'\n",
    "\n",
    "if txt_file_caption:\n",
    "    txt_file_caption_args = '--use_text_files_as_captions'\n",
    "else:\n",
    "    txt_file_caption_args = ''\n",
    "\n",
    "if aspect_ratio_bucketing:\n",
    "    aspect_ratio_bucketing_args = '--use_bucketing'\n",
    "    sample_aspect_ratio_args = '--sample_aspect_ratios'\n",
    "else:\n",
    "    aspect_ratio_bucketing_args = ''\n",
    "    sample_aspect_ratio_args = ''\n",
    "\n",
    "if new_latent_cache:\n",
    "    new_latent_cache_args = '--regenerate_latent_cache'\n",
    "else:\n",
    "    new_latent_cache_args = ''\n",
    "\n",
    "if save_latents_cache:\n",
    "    save_latents_cache_args = '--save_latents_cache'\n",
    "else:\n",
    "    save_latents_cache_args = ''\n",
    "\n",
    "if add_reg_img_dataset:\n",
    "    add_reg_img_dataset_args = '--add_class_images_to_dataset'\n",
    "else:\n",
    "    add_reg_img_dataset_args = ''\n",
    "\n",
    "if auto_balance:\n",
    "    auto_balance_args = '--auto_balance_concept_datasets'\n",
    "else:\n",
    "    auto_balance_args = ''\n",
    "\n",
    "if train_txt_encoder:\n",
    "    train_txt_encoder_args = '--train_text_encoder'\n",
    "else:\n",
    "    train_txt_encoder_args = ''\n",
    "\n",
    "if use_vae:\n",
    "    use_vae_args = '--pretrained_vae_name_or_path=stabilityai/sd-vae-ft-mse'\n",
    "else:\n",
    "    use_vae_args = '--pretrained_vae_name_or_path='\n",
    "\n",
    "if use_8bit_adam:\n",
    "    use_8bit_adam_args = '--use_8bit_adam'\n",
    "else:\n",
    "    use_8bit_adam_args = ''\n",
    "\n",
    "if use_gradient_checkpointing:\n",
    "    gradient_checkpointing_args = '--gradient_checkpointing'\n",
    "else:\n",
    "    gradient_checkpointing_args = ''\n",
    "\n",
    "if use_img_captions:\n",
    "    use_img_captions_args = '--use_image_names_as_captions'\n",
    "else:\n",
    "    use_img_captions_args = ''\n",
    "\n",
    "if use_concepts:\n",
    "    concepts_args = f'--concepts_list={concepts_file}'\n",
    "    dataset_dir_args = ''\n",
    "else:\n",
    "    concepts_args = ''\n",
    "    dataset_dir_args = f'--instance_data_dir={DATASET_DIR}'\n",
    "\n",
    "if instance_prompt != '':\n",
    "    instance_prompt_args = f'--instance_prompt={instance_prompt}'\n",
    "else:\n",
    "    instance_prompt_args = ''\n",
    "\n",
    "if class_prompt != '':\n",
    "    class_prompt_args = f'--class_prompt={class_prompt}'\n",
    "else:\n",
    "    class_prompt_args = ''\n",
    "\n",
    "if sd_base_model == 'SDv14':\n",
    "    sd_base_model_args = '--pretrained_model_name_or_path=CompVis/stable-diffusion-v1-4'\n",
    "    resolution_args = '--resolution=512'\n",
    "elif sd_base_model == 'SDv20-512':\n",
    "    sd_base_model_args = '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-base'\n",
    "    resolution_args = '--resolution=512'\n",
    "elif sd_base_model == 'SDv20-768':\n",
    "    sd_base_model_args = '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2'\n",
    "    resolution_args = '--resolution=768'\n",
    "elif sd_base_model == 'SDv21-512':\n",
    "    sd_base_model_args = '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-1-base'\n",
    "    resolution_args = '--resolution=512'\n",
    "elif sd_base_model == 'SDv21-768':\n",
    "    sd_base_model_args = '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-1'\n",
    "    resolution_args = '--resolution=768'\n",
    "else:\n",
    "    sd_base_model_args = '--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5'\n",
    "    resolution_args = '--resolution=512'\n",
    "\n",
    "if train_1024:\n",
    "    resolution_args = '--resolution=1024'\n",
    "\n",
    "if use_regularization:\n",
    "    prior_preservation_args = '--with_prior_preservation'\n",
    "    prior_preservation_weight_args = f'--prior_loss_weight={prior_preservation_weight}'\n",
    "    class_dir_args = f'--class_data_dir={CLASS_DIR}'\n",
    "else:\n",
    "    prior_preservation_args = ''\n",
    "    prior_preservation_weight_args = ''\n",
    "    class_dir_args = ''\n",
    "    num_class_images_var = 0\n",
    "\n",
    "if sample_progress:\n",
    "    num_samples_args = f'--n_save_sample={num_samples}'\n",
    "    sample_prompt_args = f'--save_sample_prompt={sample_prompt}'\n",
    "else:\n",
    "    num_samples_args = ''\n",
    "    sample_prompt_args = ''\n",
    "\n",
    "if sample_at_start:\n",
    "    sample_at_start_args = '--sample_on_training_start'\n",
    "else:\n",
    "    sample_at_start_args = ''\n",
    "\n",
    "if seed_var == '' or seed_var == '0':\n",
    "  seed_var = random.randint(1, 999999)\n",
    "else:\n",
    "  seed_var = int(seed_var)\n",
    "\n",
    "clear_output()\n",
    "print('Training ready, please proceed')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f'accelerate launch --mixed_precision={mixed_precision_var} /workspace/scripts/trainer.py \\\n",
    "    {cudnn_benchmark_args} \\\n",
    "    {txt_file_caption_args} \\\n",
    "    {use_img_captions_args} \\\n",
    "    {instance_prompt_args} \\\n",
    "    {class_prompt_args} \\\n",
    "    {sd_base_model_args} \\\n",
    "    {use_vae_args} \\\n",
    "    {resolution_args} \\\n",
    "    {aspect_ratio_bucketing_args} \\\n",
    "    {sample_aspect_ratio_args} \\\n",
    "    {new_latent_cache_args} \\\n",
    "    {save_latents_cache_args} \\\n",
    "    {auto_balance_args} \\\n",
    "    {add_reg_img_dataset_args} \\\n",
    "    {train_txt_encoder_args} \\\n",
    "    {num_samples_args} \\\n",
    "    {sample_prompt_args} \\\n",
    "    {sample_at_start_args} \\\n",
    "    {use_8bit_adam_args} \\\n",
    "    {gradient_checkpointing_args} \\\n",
    "    {concepts_args} \\\n",
    "    {dataset_dir_args} \\\n",
    "    {prior_preservation_args} \\\n",
    "    {prior_preservation_weight_args} \\\n",
    "    {class_dir_args} \\\n",
    "    --num_class_images={num_class_images_var} \\\n",
    "    --output_dir={output_dir_var} \\\n",
    "    --seed={seed_var} \\\n",
    "    --train_batch_size={batch_size_var} \\\n",
    "    --num_train_epochs={train_epochs_var} \\\n",
    "    --learning_rate={learning_rate_var} \\\n",
    "    --mixed_precision={mixed_precision_var} \\\n",
    "    --stop_text_encoder_training={txt_encoder_training_epoch_var} \\\n",
    "    --gradient_accumulation_steps={gradient_accumulation_steps_var} \\\n",
    "    --lr_scheduler={scheduler_var} \\\n",
    "    --lr_warmup_steps={scheduler_warmup_var} \\\n",
    "    --save_every_n_epoch={save_n_epoch_var} \\\n",
    "    --sample_height={sample_height_var} \\\n",
    "    --sample_width={sample_width_var} \\\n",
    "    --dataset_repeats={dataset_repeats_var} \\\n",
    "')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
